{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(in_file, max_example=None, relabeling=True):\n",
    "    \"\"\"\n",
    "        load CNN / Daily Mail data from {train | dev | test}.txt\n",
    "        relabeling: relabel the entities by their first occurence if it is True.\n",
    "    \"\"\"\n",
    "\n",
    "    documents = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    num_examples = 0\n",
    "    with open(in_file, 'r') as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            question = line.strip().lower()\n",
    "            answer = f.readline().strip()\n",
    "            document = f.readline().strip().lower()\n",
    "\n",
    "            if relabeling:\n",
    "                q_words = question.split(' ')\n",
    "                d_words = document.split(' ')\n",
    "                assert answer in d_words\n",
    "\n",
    "                entity_dict = {}\n",
    "                entity_id = 0\n",
    "                for word in d_words + q_words:\n",
    "                    if (word.startswith('@entity')) and (word not in entity_dict):\n",
    "                        entity_dict[word] = '@entity' + str(entity_id)\n",
    "                        entity_id += 1\n",
    "\n",
    "                q_words = [entity_dict[w] if w in entity_dict else w for w in q_words]\n",
    "                d_words = [entity_dict[w] if w in entity_dict else w for w in d_words]\n",
    "                answer = entity_dict[answer]\n",
    "\n",
    "                question = ' '.join(q_words)\n",
    "                document = ' '.join(d_words)\n",
    "\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "            documents.append(document)\n",
    "            num_examples += 1\n",
    "\n",
    "            f.readline()\n",
    "            if (max_example is not None) and (num_examples >= max_example):\n",
    "                break\n",
    "                \n",
    "    print('#Examples: %d' % len(documents))\n",
    "    return (documents, questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Train Loading\n",
      "#Examples: 5000\n",
      "********** Dev Loading\n",
      "#Examples: 3924\n"
     ]
    }
   ],
   "source": [
    "fin_train = 'data/cnn/train.txt'\n",
    "fin_dev = 'data/cnn/dev.txt'\n",
    "\n",
    "print('*' * 10 + ' Train Loading')\n",
    "train_d, train_q, train_a = load_data(fin_train, 5000, relabeling=True)\n",
    "print('*' * 10 + ' Dev Loading')\n",
    "dev_d, dev_q, dev_a = load_data(fin_dev, 5000, relabeling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days after two @entity0 journalists were killed in northern @entity1 , authorities rounded up dozens of suspects and a group linked to @entity2 claimed responsibility for the deaths . at least 30 suspects were seized in desert camps near the town of @entity3 and taken to the local @entity0 army base for questioning , three officials in @entity1 said . the officials did not want to be named because they are not authorized to talk to the media . @entity4 ( @entity4 ) has allegedly claimed responsibility for the killings , according to @entity5 news agency in @entity6 . @entity4 operates in northern @entity7 and the group 's statements have shown up before on the @entity8 outlet . @entity9 journalists @entity10 and @entity11 were abducted in front of the home of a member of the @entity12 rebels ' @entity13 of a @entity14 on saturday , @entity9 reported . they were found dead the same day . their bodies arrived in @entity15 on tuesday . @entity3 was one of the strongholds of the @entity16 militant @entity12 uprising last year that plunged @entity1 into chaos after a military - led coup . following the coup , @entity12 rebels occupied the northern half of the country . a response to \" crimes \" against @entity16 in @entity17 @entity4 said the killings were in response to the \" crimes \" perpetrated by @entity0 as well as @entity7 and international troops against @entity16 in @entity17 . @entity17 is an area in northern @entity1 that separatist @entity12 rebels describe as the cradle of their nomadic civilization . @entity4 said that this is just the beginning and that @entity0 president @entity18 will pay more in response to this \" new crusade \" against @entity16 , according to the purported claim . veteran @entity19 war correspondent kidnapped in @entity20 as part of @entity0 's intervention this year to flush out militants in @entity1 , the @entity0 military secured the area around @entity3 . @entity18 called an emergency meeting with ministers sunday after the killings .\n",
      "officials : the suspects were taken to the local @placeholder army base for questioning\n",
      "@entity0\n"
     ]
    }
   ],
   "source": [
    "print(train_d[0])\n",
    "print(train_q[0])\n",
    "print(train_a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dict(sentences, max_words=50000):\n",
    "    \"\"\"\n",
    "        Build a dictionary for the words in `sentences`.\n",
    "        Only the max_words ones are kept and the remaining will be mapped to <UNK>.\n",
    "    \"\"\"\n",
    "    word_count = Counter()\n",
    "    for sent in sentences:\n",
    "        for w in sent.split(' '):\n",
    "            word_count[w] += 1\n",
    "\n",
    "    ls = word_count.most_common(max_words)\n",
    "    print('#Words: %d -> %d' % (len(word_count), len(ls)))\n",
    "    for key in ls[:5]:\n",
    "        print(key)\n",
    "    print('...')\n",
    "    for key in ls[-5:]:\n",
    "        print(key)\n",
    "\n",
    "    # leave 0 to UNK\n",
    "    # leave 1 to delimiter |||\n",
    "    return {w[0]: index + 2 for (index, w) in enumerate(ls)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build dictionary..\n",
      "#Words: 41749 -> 41749\n",
      "('the', 202789)\n",
      "(',', 181868)\n",
      "('.', 155763)\n",
      "('to', 95559)\n",
      "('\"', 92261)\n",
      "...\n",
      "('columnists', 1)\n",
      "('anti-capitalist', 1)\n",
      "('67.3', 1)\n",
      "('footballs', 1)\n",
      "('non-tv', 1)\n",
      "Entity markers: 528\n"
     ]
    }
   ],
   "source": [
    "print('Build dictionary..')\n",
    "word_dict = build_dict(train_d + train_q)\n",
    "entity_markers = list(set([w for w in word_dict.keys()\n",
    "                          if w.startswith('@entity')] + train_a))\n",
    "entity_markers = ['<unk_entity>'] + entity_markers\n",
    "entity_dict = {w: index for (index, w) in enumerate(entity_markers)}\n",
    "print('Entity markers: %d' % len(entity_dict))\n",
    "num_labels = len(entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_embeddings(word_dict, dim, in_file=None):\n",
    "    \"\"\"\n",
    "        Generate an initial embedding matrix for `word_dict`.\n",
    "        If an embedding file is not given or a word is not in the embedding file,\n",
    "        a randomly initialized vector will be used.\n",
    "    \"\"\"\n",
    "\n",
    "    num_words = len(word_dict) + 2\n",
    "    embeddings = np.random.uniform(size=(num_words, dim))\n",
    "    print('Embeddings: %d x %d' % (num_words, dim))\n",
    "\n",
    "    if in_file is not None:\n",
    "        print('Loading embedding file: %s' % in_file)\n",
    "        pre_trained = 0\n",
    "        for line in open(in_file).readlines():\n",
    "            sp = line.split()\n",
    "            assert len(sp) == dim + 1 # word + embeddings ..\n",
    "            if sp[0] in word_dict:\n",
    "                pre_trained += 1\n",
    "                embeddings[word_dict[sp[0]]] = [float(x) for x in sp[1:]]\n",
    "        print('Pre-trained: %d (%.2f%%)' %\n",
    "              (pre_trained, pre_trained * 100.0 / num_words))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: 41751 x 50\n",
      "Loading embedding file: data/glove.6B/glove.6B.50d.txt\n",
      "Pre-trained: 38934 (93.25%)\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 50\n",
    "embeddings = gen_embeddings(word_dict, embedding_size, 'data/glove.6B/glove.6B.{}d.txt'.format(embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, word_dict, entity_dict, embeddings, embedding_dim, hidden_dim):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.word_dict = word_dict\n",
    "        self.embeddings = embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim // 2 * 2\n",
    "\n",
    "        self.d_gru = nn.GRU(embedding_dim, self.hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "        self.q_gru = nn.GRU(embedding_dim, self.hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "        \n",
    "        self.entity_dict = entity_dict\n",
    "        self.entity_dim = len(entity_dict)\n",
    "        self.lin = nn.Linear(self.hidden_dim, self.entity_dim)\n",
    "            \n",
    "    def init_hidden(self):\n",
    "        # Variable(num_layers*num_directions, minibatch_size, hidden_dim)\n",
    "        return Variable(torch.randn(2, 1, self.hidden_dim // 2))\n",
    "    \n",
    "    def forward(self, d, q):\n",
    "        d_words = d.split()\n",
    "        q_words = q.split()\n",
    "        d_idx = [self.word_dict[dw] for dw in d_words]\n",
    "        q_idx = [self.word_dict[qw] for qw in q_words]\n",
    "        d_emb = [self.embeddings[i] for i in d_idx] # !bug: max_words not in word_dict\n",
    "        q_emb = [self.embeddings[i] for i in q_idx]\n",
    "        d_emb = Variable(torch.FloatTensor(d_emb), requires_grad=True)\n",
    "        q_emb = Variable(torch.FloatTensor(q_emb), requires_grad=True)\n",
    "        \n",
    "        d_hidden = self.init_hidden()\n",
    "        q_hidden = self.init_hidden()\n",
    "        d_gru_out, d_hidden = self.d_gru(d_emb.view(len(d_words), 1, -1), # (seq_len, batch, input_size)\n",
    "                                         d_hidden)\n",
    "        q_gru_out, q_hidden = self.q_gru(q_emb.view(len(q_words), 1, -1), # (seq_len, batch, input_size)\n",
    "                                         q_hidden)\n",
    "        q_gru_out_mean = q_gru_out.view(len(q_words), -1).mean(dim=0)\n",
    "        \n",
    "        d_gru_out = d_gru_out.view(len(d_words), self.hidden_dim)\n",
    "        q_gru_out = q_gru_out.view(len(q_words), self.hidden_dim)\n",
    "        #sim = torch.mm(d_gru_out, q_hidden.view(self.hidden_dim,1))\n",
    "        sim = torch.mm(d_gru_out, q_gru_out_mean.view(self.hidden_dim,1))\n",
    "        o = torch.sum(d_gru_out * sim, dim=0)\n",
    "        \n",
    "        ol = self.lin(o)\n",
    "        dummy = Variable(torch.FloatTensor([float('-inf')] * self.entity_dim))\n",
    "        ol2 = torch.cat((ol.view(-1,1), dummy.view(-1,1)), dim=1)\n",
    "        d_ent_idx = set(list(filter(lambda x: x, \n",
    "                                [self.entity_dict.get(dw, None)\n",
    "                                 for dw in d_words])))\n",
    "        o_idx = [0 if i in d_ent_idx else 1 for i in range(self.entity_dim)]\n",
    "        o = ol2.gather(1, Variable(torch.Tensor(o_idx).long().view(-1,1)))\n",
    "        \n",
    "        return F.log_softmax(o, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNT 0, Loss: 49.76732635498047\n",
      "COUNT 50, Loss: 21.61507225036621\n",
      "COUNT 100, Loss: 19.04601287841797\n",
      "COUNT 150, Loss: 16.15447235107422\n",
      "COUNT 200, Loss: 37.97210693359375\n",
      "COUNT 250, Loss: 7.783970355987549\n",
      "COUNT 300, Loss: 1.9780786037445068\n",
      "COUNT 350, Loss: 13.490550994873047\n",
      "COUNT 400, Loss: 9.612691879272461\n",
      "COUNT 450, Loss: 25.18260955810547\n",
      "COUNT 500, Loss: 20.973920822143555\n",
      "COUNT 550, Loss: 1.982447862625122\n",
      "COUNT 600, Loss: 11.927663803100586\n",
      "COUNT 650, Loss: 2.5551300048828125\n",
      "COUNT 700, Loss: 11.45595932006836\n",
      "COUNT 750, Loss: 4.142070293426514\n",
      "COUNT 800, Loss: 21.09282112121582\n",
      "COUNT 850, Loss: 3.4850857257843018\n",
      "COUNT 900, Loss: 18.67911720275879\n",
      "COUNT 950, Loss: 4.437651634216309\n",
      "COUNT 1000, Loss: 9.375301361083984\n",
      "COUNT 1050, Loss: 3.015742301940918\n",
      "COUNT 1100, Loss: 2.899275541305542\n",
      "COUNT 1150, Loss: 3.163215160369873\n",
      "COUNT 1200, Loss: 1.8998486995697021\n",
      "COUNT 1250, Loss: 1.50186288356781\n",
      "COUNT 1300, Loss: 3.5696892738342285\n",
      "COUNT 1350, Loss: 3.40248703956604\n",
      "COUNT 1400, Loss: 3.3709359169006348\n",
      "COUNT 1450, Loss: 2.2916696071624756\n",
      "COUNT 1500, Loss: 9.379899024963379\n",
      "COUNT 1550, Loss: 1.528336763381958\n",
      "COUNT 1600, Loss: 3.0868451595306396\n",
      "COUNT 1650, Loss: 2.2585322856903076\n",
      "COUNT 1700, Loss: 0.22723780572414398\n",
      "COUNT 1750, Loss: 3.4466962814331055\n",
      "COUNT 1800, Loss: 6.145534038543701\n",
      "COUNT 1850, Loss: 8.208611488342285\n",
      "COUNT 1900, Loss: 2.4935669898986816\n",
      "COUNT 1950, Loss: 1.4374827146530151\n",
      "COUNT 2000, Loss: 13.332050323486328\n",
      "COUNT 2050, Loss: 2.5126545429229736\n",
      "COUNT 2100, Loss: 2.6489450931549072\n",
      "COUNT 2150, Loss: 2.1053659915924072\n",
      "COUNT 2200, Loss: 2.2109735012054443\n",
      "COUNT 2250, Loss: 2.088810443878174\n",
      "COUNT 2300, Loss: 1.9524022340774536\n",
      "COUNT 2350, Loss: 3.877025604248047\n",
      "COUNT 2400, Loss: 2.015625476837158\n",
      "COUNT 2450, Loss: 1.9696471691131592\n",
      "COUNT 2500, Loss: 2.588996648788452\n",
      "COUNT 2550, Loss: 7.156141757965088\n",
      "COUNT 2600, Loss: 1.8654274940490723\n",
      "COUNT 2650, Loss: 3.2063069343566895\n",
      "COUNT 2700, Loss: 2.225698471069336\n",
      "COUNT 2750, Loss: 1.3635319471359253\n",
      "COUNT 2800, Loss: 2.564206838607788\n",
      "COUNT 2850, Loss: 1.559290885925293\n",
      "COUNT 2900, Loss: 6.231446743011475\n",
      "COUNT 2950, Loss: 4.302574157714844\n",
      "COUNT 3000, Loss: 3.010183095932007\n",
      "COUNT 3050, Loss: 8.523175239562988\n",
      "COUNT 3100, Loss: 2.289666175842285\n",
      "COUNT 3150, Loss: 3.2964365482330322\n",
      "COUNT 3200, Loss: 4.58371114730835\n",
      "COUNT 3250, Loss: 1.8921549320220947\n",
      "COUNT 3300, Loss: 1.9347184896469116\n",
      "COUNT 3350, Loss: 2.14564847946167\n",
      "COUNT 3400, Loss: 2.9062323570251465\n",
      "COUNT 3450, Loss: 11.036352157592773\n",
      "COUNT 3500, Loss: 2.4883790016174316\n",
      "COUNT 3550, Loss: 3.328827142715454\n",
      "COUNT 3600, Loss: 0.720293402671814\n",
      "COUNT 3650, Loss: 2.4088871479034424\n",
      "COUNT 3700, Loss: 2.7518222332000732\n",
      "COUNT 3750, Loss: 2.932460308074951\n",
      "COUNT 3800, Loss: 2.4682979583740234\n",
      "COUNT 3850, Loss: 9.068382263183594\n",
      "COUNT 3900, Loss: 3.153395414352417\n",
      "COUNT 3950, Loss: 1.678687572479248\n",
      "COUNT 4000, Loss: 4.009546756744385\n",
      "COUNT 4050, Loss: 4.617773532867432\n",
      "COUNT 4100, Loss: 3.4772579669952393\n",
      "COUNT 4150, Loss: 2.3567020893096924\n",
      "COUNT 4200, Loss: 2.6212265491485596\n",
      "COUNT 4250, Loss: 9.755270004272461\n",
      "COUNT 4300, Loss: 2.8355071544647217\n",
      "COUNT 4350, Loss: 4.774375915527344\n",
      "COUNT 4400, Loss: 5.04801607131958\n",
      "COUNT 4450, Loss: 3.2440967559814453\n",
      "COUNT 4500, Loss: 4.059027194976807\n",
      "COUNT 4550, Loss: 2.922649383544922\n",
      "COUNT 4600, Loss: 8.175649642944336\n",
      "COUNT 4650, Loss: 1.6566157341003418\n",
      "COUNT 4700, Loss: 2.260977029800415\n",
      "COUNT 4750, Loss: 3.9669296741485596\n",
      "COUNT 4800, Loss: 5.764330863952637\n",
      "COUNT 4850, Loss: 3.8591644763946533\n",
      "COUNT 4900, Loss: 2.644507646560669\n",
      "COUNT 4950, Loss: 2.2381513118743896\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x101e90828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "hidden_dim = 5\n",
    "net = Net(word_dict, entity_dict, embeddings, embedding_size, hidden_dim)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "losses = list()\n",
    "cnt = 0\n",
    "for i,d,q,a in zip(range(len(train_a)), train_d, train_q, train_a): # !test\n",
    "    net.zero_grad()\n",
    "    log_probs = net(d, q)\n",
    "    target = Variable(torch.LongTensor([entity_dict[a]]))\n",
    "    loss = loss_function(log_probs.view(1,-1), target)\n",
    "    losses.append(loss.data.numpy().tolist()[0])\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(net.parameters(), 1)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print('COUNT {}, Loss: {}'.format(i, losses[-1]))\n",
    "plt.plot(range(len(losses)), losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.15\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "sz = 1000\n",
    "for i,d,q,a in zip(range(len(train_a)), train_d, train_q, train_a): # !test\n",
    "    if i >= sz:\n",
    "        break\n",
    "        \n",
    "    log_probs = net(d, q)\n",
    "    target = entity_dict[a]\n",
    "    _, idx = torch.max(log_probs, 0)\n",
    "    acc += idx.data.numpy().tolist()[0] == target\n",
    "#print('acc: {}'.format(acc/len(train_a)))\n",
    "print('acc: {}'.format(acc/sz))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
